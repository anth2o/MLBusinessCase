{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import preprocessing as pp\n",
    "import model\n",
    "from train import train_model\n",
    "from predict import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data loading\n",
    "df_store = pd.read_csv('../data/store.csv')\n",
    "df_train = pd.read_csv('../data/train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General pipeline test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection (Time-split cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1: RSME = 1021.030575494208 | R² = 0.8773542416937264\n",
      "FOLD 2: RSME = 1034.2511374965702 | R² = 0.8740763328250686\n",
      "FOLD 3: RSME = 1375.6073013301593 | R² = 0.8064136150900911\n",
      "FOLD 4: RSME = 953.7371352484539 | R² = 0.8946355191205734\n",
      "FOLD 5: RSME = 1185.8121245991567 | R² = 0.847408331632223\n",
      "FOLD 6: RSME = 1152.575591317617 | R² = 0.8456257887762073\n",
      "FOLD 7: RSME = 1038.42823564974 | R² = 0.8648170891924178\n",
      "FOLD 8: RSME = 1050.8495749655294 | R² = 0.8649525654901132\n",
      "FOLD 9: RSME = 1475.3725778797975 | R² = 0.8053101498271293\n",
      "FOLD 10: RSME = 1145.386963215362 | R² = 0.8594035177072104\n",
      "--- OVERALL ---\n",
      "RSME = 1162.00 | R² = 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from train import rmse, r2\n",
    "\n",
    "train = df_train.copy().iloc[::-1]\n",
    "train.Date = pd.to_datetime(train.Date)\n",
    "\n",
    "n_splits = 10\n",
    "test_size = 42\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "reg_model = model.Regressor()\n",
    "rmse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "date_grouping = train.groupby(train.Date)['Store']\n",
    "date_list = [g[0] for g in list(date_grouping)[:]]\n",
    "for train_index, test_index in tscv.split(date_grouping):\n",
    "    \n",
    "    # Fixed test set cardinality (in number of days)\n",
    "    train_index = np.append(train_index, list(range(len(train_index), 1 + int(test_index[-1] - test_size))))\n",
    "    test_index = test_index[(1 + int(train_index[-1] - test_index[0])):]\n",
    "    \n",
    "    train_dates = [date_list[train_index[0]], date_list[train_index[-1]]]\n",
    "    test_dates = [date_list[test_index[0]], date_list[test_index[-1]]]\n",
    "    train_mask = (train.Date >= train_dates[0]) & (train.Date <= train_dates[1])\n",
    "    test_mask = (train.Date >= test_dates[0]) & (train.Date <= test_dates[1])\n",
    "    \n",
    "    # Train and test sets\n",
    "    X_train, y_train, X_PCA_train = pp.Preprocessor().transform(df_store, train.loc[train_mask])\n",
    "    X_test, y_test, X_PCA_test = pp.Preprocessor().transform(df_store, train.loc[test_mask])\n",
    "    \n",
    "    # Dummy variables can induce differences in the schemas\n",
    "    missing_test = set(X_train.columns) - set(X_test.columns)\n",
    "    missing_train = set(X_test.columns) - set(X_train.columns)\n",
    "    for c in missing_test:\n",
    "        X_test[c] = 0\n",
    "    for c in missing_train:\n",
    "        X_train[c] = 0\n",
    "    # Reorder to match columns order in train and test\n",
    "    X_test = X_test[X_train.columns]\n",
    "    \n",
    "    # Model fitting on training set\n",
    "    train_model(reg_model, X_train, y_train)\n",
    "\n",
    "    # Scoring on test set\n",
    "    y_pred = reg_model.predict(X_test)\n",
    "    rmse_scores.append(rmse(y_test, y_pred))\n",
    "    r2_scores.append(r2(y_test, y_pred))\n",
    "        \n",
    "# Final display\n",
    "for i in range(n_splits):\n",
    "    print(\"FOLD \" + str(i + 1) + \": \" + \"RSME = \" + str(rmse_scores[i]) + \n",
    "      \" | R² = \" + str(r2_scores[i]))\n",
    "    \n",
    "# Overall scores\n",
    "w = [1 + 0.5 * i for i in range(1, n_splits + 1)]\n",
    "print(\"--- OVERALL ---\")\n",
    "print(\"RSME = \" + '{0:.2f}'.format(np.average(rmse_scores, weights=w)) + \" | R² = \" + '{0:.2f}'.format(np.average(r2_scores, weights=w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection (Held-out test set of the last 6 weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME = 1139.4394499325153 | R² = 0.859883338523965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from train import rmse, r2\n",
    "\n",
    "train = df_train.copy().iloc[::-1]\n",
    "train.Date = pd.to_datetime(train.Date)\n",
    "train_set = train[train.Date < '2015-06-19']\n",
    "test_set = train[train.Date >= '2015-06-19']\n",
    "\n",
    "reg_model = model.Regressor()\n",
    "rmse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "X_train, y_train, X_PCA_train = pp.Preprocessor().transform(df_store, train_set)\n",
    "X_test, y_test, X_PCA_test = pp.Preprocessor().transform(df_store, test_set)\n",
    "\n",
    "# Dummy variables can induce differences in the schemas\n",
    "missing_test = set(X_train.columns) - set(X_test.columns)\n",
    "missing_train = set(X_test.columns) - set(X_train.columns)\n",
    "for c in missing_test:\n",
    "    X_test[c] = 0\n",
    "for c in missing_train:\n",
    "    X_train[c] = 0\n",
    "# Reorder to match columns order in train and test\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# Model fitting on training set\n",
    "train_model(reg_model, X_train, y_train)\n",
    "\n",
    "# Scoring on test set\n",
    "y_pred = reg_model.predict(X_test)\n",
    "rmse_scores = rmse(y_test, y_pred)\n",
    "r2_scores = r2(y_test, y_pred)\n",
    "\n",
    "print(\"RSME = \" + str(rmse_scores) + \" | R² = \" + str(r2_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.224832 (0.041618)\n",
      "XGB: 0.385410 (0.032406)\n",
      "RF: 0.870310 (0.017098)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('XGB', XGBRegressor()))\n",
    "models.append(('RF', RandomForestRegressor()))\n",
    "\n",
    "std = StandardScaler()\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "train = df_train.copy().iloc[::-1]\n",
    "train.Date = pd.to_datetime(train.Date)\n",
    "\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "date_grouping = train.groupby(train.Date)['Store']\n",
    "date_list = [g[0] for g in list(date_grouping)[:]]\n",
    "\n",
    "for name, model in models:\n",
    "    r2_scores = []\n",
    "    \n",
    "    for train_index, test_index in tscv.split(date_grouping):\n",
    "        # Fixed test set cardinality (in number of days)\n",
    "        train_index = np.append(train_index, list(range(len(train_index), 1 + int(test_index[-1] - test_size))))\n",
    "        test_index = test_index[(1 + int(train_index[-1] - test_index[0])):]\n",
    "\n",
    "        train_dates = [date_list[train_index[0]], date_list[train_index[-1]]]\n",
    "        test_dates = [date_list[test_index[0]], date_list[test_index[-1]]]\n",
    "        train_mask = (train.Date >= train_dates[0]) & (train.Date <= train_dates[1])\n",
    "        test_mask = (train.Date >= test_dates[0]) & (train.Date <= test_dates[1])\n",
    "\n",
    "        # Train and test sets\n",
    "        X_train, y_train, X_PCA_train = pp.Preprocessor().transform(df_store, train.loc[train_mask])\n",
    "        X_test, y_test, X_PCA_test = pp.Preprocessor().transform(df_store, train.loc[test_mask])\n",
    "        \n",
    "         # Train and test sets\n",
    "        X_train, y_train, X_PCA_train = pp.Preprocessor().transform(df_store, train.loc[train_mask])\n",
    "        X_test, y_test, X_PCA_test = pp.Preprocessor().transform(df_store, train.loc[test_mask])\n",
    "\n",
    "        # Dummy variables can induce differences in the schemas\n",
    "        missing_test = set(X_train.columns) - set(X_test.columns)\n",
    "        missing_train = set(X_test.columns) - set(X_train.columns)\n",
    "        for c in missing_test:\n",
    "            X_test[c] = 0\n",
    "        for c in missing_train:\n",
    "            X_train[c] = 0\n",
    "        # Reorder to match columns order in train and test\n",
    "        X_test = X_test[X_train.columns]\n",
    "        \n",
    "        X_train = std.fit_transform(X_train.loc[:, X_train.columns != 'Date'])\n",
    "        X_test = std.transform(X_test.loc[:, X_test.columns != 'Date'])\n",
    "\n",
    "        # Model fitting on training set\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Scoring on test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        r2_scores.append(r2(y_test, y_pred))\n",
    "    \n",
    "    results.append(r2_scores)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, np.mean(r2_scores), np.std(r2_scores))\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAKGCAYAAADZBnM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAwm2gAAAAb7f0Qe2DAmecngAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data loading\n",
    "df_store = pd.read_csv('../data/store.csv')\n",
    "df_train = pd.read_csv('../data/train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(844392, 22) (844392,) (844392, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StateHoliday_a</th>\n",
       "      <th>StateHoliday_b</th>\n",
       "      <th>StateHoliday_c</th>\n",
       "      <th>cos_DayOfWeek</th>\n",
       "      <th>sin_DayOfWeek</th>\n",
       "      <th>...</th>\n",
       "      <th>PromoInterval_Feb,May,Aug,Nov</th>\n",
       "      <th>PromoInterval_Jan,Apr,Jul,Oct</th>\n",
       "      <th>PromoInterval_Mar,Jun,Sept,Dec</th>\n",
       "      <th>StoreType_b</th>\n",
       "      <th>StoreType_c</th>\n",
       "      <th>StoreType_d</th>\n",
       "      <th>Assortment_b</th>\n",
       "      <th>Assortment_c</th>\n",
       "      <th>CompetitionOpenSince</th>\n",
       "      <th>Promo2Since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>648.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>648.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-07-29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>648.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-07-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>648.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>648.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DayOfWeek        Date  Open  Promo  SchoolHoliday  StateHoliday_a  \\\n",
       "0          5  2015-07-31     1      1              1               0   \n",
       "1          4  2015-07-30     1      1              1               0   \n",
       "2          3  2015-07-29     1      1              1               0   \n",
       "3          2  2015-07-28     1      1              1               0   \n",
       "4          1  2015-07-27     1      1              1               0   \n",
       "\n",
       "   StateHoliday_b  StateHoliday_c  cos_DayOfWeek  sin_DayOfWeek     ...       \\\n",
       "0               0               0      -0.222521      -0.974928     ...        \n",
       "1               0               0      -0.900969      -0.433884     ...        \n",
       "2               0               0      -0.900969       0.433884     ...        \n",
       "3               0               0      -0.222521       0.974928     ...        \n",
       "4               0               0       0.623490       0.781831     ...        \n",
       "\n",
       "   PromoInterval_Feb,May,Aug,Nov  PromoInterval_Jan,Apr,Jul,Oct  \\\n",
       "0                              0                              0   \n",
       "1                              0                              0   \n",
       "2                              0                              0   \n",
       "3                              0                              0   \n",
       "4                              0                              0   \n",
       "\n",
       "   PromoInterval_Mar,Jun,Sept,Dec  StoreType_b  StoreType_c  StoreType_d  \\\n",
       "0                               0            0            1            0   \n",
       "1                               0            0            1            0   \n",
       "2                               0            0            1            0   \n",
       "3                               0            0            1            0   \n",
       "4                               0            0            1            0   \n",
       "\n",
       "   Assortment_b  Assortment_c  CompetitionOpenSince  Promo2Since  \n",
       "0             0             0                 105.0   648.142857  \n",
       "1             0             0                 105.0   648.142857  \n",
       "2             0             0                 105.0   648.142857  \n",
       "3             0             0                 105.0   648.142857  \n",
       "4             0             0                 105.0   648.142857  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "X, y, X_PCA = pp.Preprocessor().transform(df_store, df_train)\n",
    "print(X.shape, y.shape, X_PCA.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = model.Regressor()\n",
    "train_model(reg_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor()\n"
     ]
    }
   ],
   "source": [
    "print(reg_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
